[Numerical Python] 
- Scientific Computing and Data Science Applecations With Numpy,SciPy and Matplotlib (+Pandus)
- AI > Machine Learning > Deep Learning 
- 제공 도구: Tensorflow, PyTorch, SKlearn

[Perceptron Examples] 
- Perceptron: 눈으로 인지하는 것, 시각 세포, 컴퓨터가 사람의 눈처럼 인지/구분할 수 있는가?
- [입력 -> Perceptron -> 출력] 구조 
- Supervising : 입력과 출력간의 관계 결정 (<->Unsupervising)
- Error 발생시 Input에 사용되는 Weight 값을 update -> Learning (=training, fit, optimize)
  Error가 특정 값보다 낮아질 때까지 반복 (반복 횟수: epoch)
- activation function 종류: Unit step, Linear, Logistic(sigmoid), Hyperbolic tangent(sigmoid)
- 위 함수 중 적합한 것을 적용해야 weight update를 잘 할 수 있음
- learning rate가 적당해야 함. 너무 크거나 작으면 X
- Error Backpropagation 
- Convoutional Neural Networks (CNN): EBP가 핵심
- Canadian Institute for Advanced Research (CIFAR)
- Neural Network = Deep Learning
- 점점 더 정확도를 높이는 모델 많아지고 있음
- Keras: Tensorflow의 코드 수를 줄이기 위함 
- Array vs Tensor
  : 둘 다 메모리에 존재. Array 데이터를 Tensor로 바꿈. Tensor로 묶여진 것만 GPU로 들어갈 수 있음(cpu보다 속도up, 데이터를 병렬 처리하기 때문)
    Pytorch는 GPU가 없어도 tensor 처리 가능, Tensorflow는 GPU버전이 따로 존재 

Basic Example
- MLP: Multi layer perceptron 
- x 입력 y 출력 : List
- data set: X = [[0., 0.], [0., 1.], [1., 0.],  [1., 1.]], y = [[0,0],[1,0], [1,0],[0,1]]
- model: hidden_layer_sizes=(6,4), random_state=100, activation='logistic', max_iter=200)
- node 많을수록 세밀한 학습 (but 너무 많아도 좋지 않음)
- .T: Transpose 행과 열의 위치를 바꿈 -> 병렬로 계산하기위함
- tensor: torch가 사용하는 array
- pytorch 장점: 모델만 정하면 알아서 학습시켜줌
- tensorflow: data flow를 모델링




